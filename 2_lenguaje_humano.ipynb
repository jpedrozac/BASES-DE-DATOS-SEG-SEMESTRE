{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpedrozac/BASES-DE-DATOS-SEG-SEMESTRE/blob/main/2_lenguaje_humano.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Primeros pasos con los idiomas**\n",
        "La búsqueda de texto completo es una batalla entre la precisión (devolver la menor cantidad posible de documentos irrelevantes) y la memoria (devolver la mayor cantidad posible de documentos relevantes).\n",
        "\n",
        "Se pueden implementar muchas tácticas para abordar la precisión y la memoria, como la modificación de palabras: p. busque \"saltando\", \"salta\" y \"saltó\" reduciendo las palabras a su raíz (raíz) - \"saltar\".\n",
        "\n",
        "Sin embargo, el primer paso es identificar palabras usando un analizador.\n",
        "\n",
        "* **Tokenize texto en palabras individuales:**\n",
        "Los veloces zorros marrones → [Los, veloces, zorros, marrones]\n",
        "* **Lowercase tokens:**\n",
        "Los → los\n",
        "* **Stem tokens a su forma raíz:**\n",
        "zorros → zorro\n",
        "* **Remover StopWords:**\n",
        "[Los, veloces, zorros, marrones] → [veloces, zorros, marrones]\n",
        "\n"
      ],
      "metadata": {
        "id": "OQja7_j-uXFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#instalamos las librerias de ElasticSearch\n",
        "!pip install elasticsearch\n",
        "!pip install elasticsearch-dsl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d95WC7bDBBAX",
        "outputId": "6d0088ee-75fb-4277-80c8-aee4bbd06aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting elasticsearch\n",
            "  Downloading elasticsearch-8.13.1-py3-none-any.whl (477 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m477.5/477.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting elastic-transport<9,>=8.13 (from elasticsearch)\n",
            "  Downloading elastic_transport-8.13.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8.13->elasticsearch) (2.0.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8.13->elasticsearch) (2024.2.2)\n",
            "Installing collected packages: elastic-transport, elasticsearch\n",
            "Successfully installed elastic-transport-8.13.0 elasticsearch-8.13.1\n",
            "Collecting elasticsearch-dsl\n",
            "  Downloading elasticsearch_dsl-8.13.1-py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from elasticsearch-dsl) (2.8.2)\n",
            "Requirement already satisfied: elasticsearch<9.0.0,>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from elasticsearch-dsl) (8.13.1)\n",
            "Requirement already satisfied: elastic-transport<9,>=8.13 in /usr/local/lib/python3.10/dist-packages (from elasticsearch<9.0.0,>=8.0.0->elasticsearch-dsl) (8.13.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->elasticsearch-dsl) (1.16.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8.13->elasticsearch<9.0.0,>=8.0.0->elasticsearch-dsl) (2.0.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8.13->elasticsearch<9.0.0,>=8.0.0->elasticsearch-dsl) (2024.2.2)\n",
            "Installing collected packages: elasticsearch-dsl\n",
            "Successfully installed elasticsearch-dsl-8.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar el cliente desde el módulo 'elasticsearch'\n",
        "from elasticsearch import Elasticsearch\n",
        "from elasticsearch_dsl import Search, Q\n",
        "from elasticsearch.exceptions import NotFoundError, RequestError\n",
        "from pprint import pprint\n",
        "import json"
      ],
      "metadata": {
        "id": "e9iZwAyPCvbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# agregue su string de conexión\n",
        "CLOUD_ID = \"51ba68e5b9a4413e9a86103666932c48:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvOjQ0MyRiYmEyYzlkZWJhYjc0YjJhOThjZjVlMTQ2N2E4YTY3MiQwMGVhZTM4MDU5NTQ0MTIwYjY1NjdjMTExYWJhMDI4Mg==\"\n",
        "es = Elasticsearch(\n",
        "    cloud_id=CLOUD_ID,\n",
        "    http_auth=(\"elastic\", \"iHa85Y0HRHo4eEIsBvsBB5z7\")\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkylFzIy0rYU",
        "outputId": "aaf8c821-e8b9-4589-8af5-6a8efdb0c613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-a5948f97f838>:3: DeprecationWarning: The 'http_auth' parameter is deprecated. Use 'basic_auth' or 'bearer_auth' parameters instead\n",
            "  es = Elasticsearch(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# La sisguiente instrucción muestra los datos de la instalación de elastic\n",
        "# Obtener la información del servidor\n",
        "info = es.info()\n",
        "\n",
        "# Extraer y mostrar solo la versión\n",
        "version = info.get('version', {}).get('number')\n",
        "print(\"Elasticsearch version:\", version)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzuBHRFSC9Bp",
        "outputId": "3eb19599-45dc-4c80-91e6-505c89e1ece5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elasticsearch version: 8.13.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Borrar el índice si existe\n",
        "index_name = 'my_index'\n",
        "try:\n",
        "    response = es.indices.delete(index=index_name)\n",
        "    print(f\"Índice '{index_name}' borrado:\", response)\n",
        "except NotFoundError:\n",
        "    print(f\"Índice '{index_name}' no existe, por lo tanto no se borró.\")\n",
        "except RequestError as e:\n",
        "    if e.error == 'index_not_found_exception':\n",
        "        print(f\"Índice '{index_name}' no encontrado, por lo tanto no se borró.\")\n",
        "    else:\n",
        "        print(f\"Error al intentar borrar el índice '{index_name}':\", e.info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDLK2dwdLh3t",
        "outputId": "d0046640-aeb0-41be-c3c9-c7020ac6d70f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Índice 'my_index' borrado: {'acknowledged': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creamos un Índice con Stemming:\n",
        "\n",
        "Se define un analizador personalizado spanish_analyzer que incluye un filtro **spanish_stemmer** para reducir las palabras a sus raíces.\n",
        "El campo title está configurado para usar este analizado"
      ],
      "metadata": {
        "id": "Eqv3DGmnLg75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "index_template = {\n",
        "    \"settings\": {\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"spanish_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"standard\",\n",
        "                    \"filter\": [\n",
        "                        \"lowercase\",\n",
        "                        \"spanish_stop\",\n",
        "                        \"spanish_stemmer\"\n",
        "                    ]\n",
        "                }\n",
        "            },\n",
        "            \"filter\": {\n",
        "                \"spanish_stop\": {\n",
        "                    \"type\": \"stop\",\n",
        "                    \"stopwords\": \"_spanish_\"\n",
        "                },\n",
        "                \"spanish_stemmer\": {\n",
        "                    \"type\": \"stemmer\",\n",
        "                    \"language\": \"light_spanish\"\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"title\": {\n",
        "                \"type\": \"text\",\n",
        "                \"analyzer\": \"spanish_analyzer\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "lSLGoyK4OYb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea un indece segun la plantilla creada\n",
        "es.indices.create(index='my_index', body=index_template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBipIbwqF6RO",
        "outputId": "87b23008-e5e5-4025-c886-9e392cbc635c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'my_index'})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a insertar datos en nuestro indice"
      ],
      "metadata": {
        "id": "E6kNRR2jGAZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    { \"title\": \"Estoy feliz por este zorro\" },\n",
        "    { \"title\": \"No estoy contento con mi problema del zorro\" },\n",
        "    { \"title\": \"Los zorros son astutos y rápidos\" },  # Documento con \"zorros\"\n",
        "    { \"title\": \"Los perros no están contentos hoy\" },\n",
        "    { \"title\": \"Los gatos son felices en el sol\" }\n",
        "]\n",
        "\n",
        "# Indexar los documentos\n",
        "for i, doc in enumerate(documents):\n",
        "    es.index(index='my_index', body=doc, id=i+1)"
      ],
      "metadata": {
        "id": "oXd0imquHIHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Consultas con elasticsearch-dsl\n"
      ],
      "metadata": {
        "id": "io2BZP4bK25M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar una búsqueda\n",
        "s = Search(using=es, index='my_index')\n",
        "q = Q('match', title='zorros')\n",
        "s = s.query(q)\n",
        "res = s.execute()\n",
        "\n",
        "# Imprimir los resultados\n",
        "for hit in res:\n",
        "    print(hit.meta.id, hit.title, ' - Score:', hit.meta.score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-we3ax7IRUf",
        "outputId": "6554b3af-dd42-4f12-ddb9-8faa81ed69d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Estoy feliz por este zorro  - Score: 0.6103343\n",
            "2 No estoy contento con mi problema del zorro  - Score: 0.52369374\n",
            "3 Los zorros son astutos y rápidos  - Score: 0.52369374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tenga en cuenta que ambos hits no contienen la palabra **zorros**, pero obtuvimos resultado con la palabra zorro.\n",
        "\n",
        "Este enfoque asegura que las búsquedas sean más flexibles y encuentren documentos que contienen diferentes formas de una palabra basada en su raíz."
      ],
      "metadata": {
        "id": "rif8wB-BBvDc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Normalizando Tokens\n",
        "Dividir el texto en tokens es solo la mitad del trabajo. Para que esos tokens se puedan buscar más fácilmente, deben pasar por un proceso de normalización para eliminar las diferencias insignificantes entre palabras idénticas, como mayúsculas y minúsculas. Tal vez también necesitemos eliminar las diferencias significativas, para hacer que esta, ésta y está sean todas buscables como la misma palabra. ¿Buscarías un déjà vu, o simplemente un deja vu?\n",
        "\n",
        "Este es el trabajo de los filtros de tokens, que reciben un flujo de tokens del tokenizador. Puede tener múltiples filtros de token, cada uno haciendo su trabajo particular. Cada uno recibe el nuevo flujo de token como resultado del filtro de token anterior.\n",
        "\n",
        "* **Tipos de Tokenizadores:**\n",
        "\t- Standard\n",
        "\t- Simple\n",
        "\t- Whitespace\n",
        "\t- Stop\n",
        "\t- Keyword\n",
        "\t- Pattern\n",
        "\t- Fingerprint"
      ],
      "metadata": {
        "id": "Fif7HT4cKVOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos un array con los diferentes analizadores que existen en Elastic.\n",
        "analyzer = ['standard','simple','whitespace','stop','keyword','pattern','fingerprint','english']\n",
        "\n",
        "#Imprimimos los diferentes analizadores con el mismo texto\n",
        "for analize in analyzer:\n",
        "    res = es.indices.analyze(body={\n",
        "        \"analyzer\" : analize,\n",
        "        \"text\" : [\"HOLA MUNDO. ¡¡¡Hoy es el 2nd día de la semana!!!! es lunes. Por favor envíame un correo electrónico a friend@ucentral.edu.co\"]\n",
        "\n",
        "    })\n",
        "    print(\"*****\",analize,\"*****\")\n",
        "    for i in res['tokens']:\n",
        "        print(i['token'])\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0H1rEdELJHE",
        "outputId": "a7f4abb8-9bab-4c1e-a8af-ce7b5f40645c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** standard *****\n",
            "hola\n",
            "mundo\n",
            "hoy\n",
            "es\n",
            "el\n",
            "2nd\n",
            "día\n",
            "de\n",
            "la\n",
            "semana\n",
            "es\n",
            "lunes\n",
            "por\n",
            "favor\n",
            "envíame\n",
            "un\n",
            "correo\n",
            "electrónico\n",
            "a\n",
            "friend\n",
            "ucentral.edu.co\n",
            "\n",
            "\n",
            "***** simple *****\n",
            "hola\n",
            "mundo\n",
            "hoy\n",
            "es\n",
            "el\n",
            "nd\n",
            "día\n",
            "de\n",
            "la\n",
            "semana\n",
            "es\n",
            "lunes\n",
            "por\n",
            "favor\n",
            "envíame\n",
            "un\n",
            "correo\n",
            "electrónico\n",
            "a\n",
            "friend\n",
            "ucentral\n",
            "edu\n",
            "co\n",
            "\n",
            "\n",
            "***** whitespace *****\n",
            "HOLA\n",
            "MUNDO.\n",
            "¡¡¡Hoy\n",
            "es\n",
            "el\n",
            "2nd\n",
            "día\n",
            "de\n",
            "la\n",
            "semana!!!!\n",
            "es\n",
            "lunes.\n",
            "Por\n",
            "favor\n",
            "envíame\n",
            "un\n",
            "correo\n",
            "electrónico\n",
            "a\n",
            "friend@ucentral.edu.co\n",
            "\n",
            "\n",
            "***** stop *****\n",
            "hola\n",
            "mundo\n",
            "hoy\n",
            "es\n",
            "el\n",
            "nd\n",
            "día\n",
            "de\n",
            "la\n",
            "semana\n",
            "es\n",
            "lunes\n",
            "por\n",
            "favor\n",
            "envíame\n",
            "un\n",
            "correo\n",
            "electrónico\n",
            "friend\n",
            "ucentral\n",
            "edu\n",
            "co\n",
            "\n",
            "\n",
            "***** keyword *****\n",
            "HOLA MUNDO. ¡¡¡Hoy es el 2nd día de la semana!!!! es lunes. Por favor envíame un correo electrónico a friend@ucentral.edu.co\n",
            "\n",
            "\n",
            "***** pattern *****\n",
            "hola\n",
            "mundo\n",
            "hoy\n",
            "es\n",
            "el\n",
            "2nd\n",
            "d\n",
            "a\n",
            "de\n",
            "la\n",
            "semana\n",
            "es\n",
            "lunes\n",
            "por\n",
            "favor\n",
            "env\n",
            "ame\n",
            "un\n",
            "correo\n",
            "electr\n",
            "nico\n",
            "a\n",
            "friend\n",
            "ucentral\n",
            "edu\n",
            "co\n",
            "\n",
            "\n",
            "***** fingerprint *****\n",
            "2nd a correo de dia el electronico enviame es favor friend hola hoy la lunes mundo por semana ucentral.edu.co un\n",
            "\n",
            "\n",
            "***** english *****\n",
            "hola\n",
            "mundo\n",
            "hoi\n",
            "es\n",
            "el\n",
            "2nd\n",
            "día\n",
            "de\n",
            "la\n",
            "semana\n",
            "es\n",
            "lune\n",
            "por\n",
            "favor\n",
            "envíam\n",
            "un\n",
            "correo\n",
            "electrónico\n",
            "friend\n",
            "ucentral.edu.co\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Stop Words\n",
        "Para usar stopwords personalizadas junto con el analizador estándar, todo lo que tenemos que hacer es crear una versión configurada del analizador y pasar la lista de stopwords que necesitamos:"
      ],
      "metadata": {
        "id": "ZO9G3CkjMnTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Borrar el índice si existe\n",
        "index_name = 'my_index'\n",
        "try:\n",
        "    response = es.indices.delete(index=index_name)\n",
        "    print(f\"Índice '{index_name}' borrado:\", response)\n",
        "except NotFoundError:\n",
        "    print(f\"Índice '{index_name}' no existe, por lo tanto no se borró.\")\n",
        "except RequestError as e:\n",
        "    if e.error == 'index_not_found_exception':\n",
        "        print(f\"Índice '{index_name}' no encontrado, por lo tanto no se borró.\")\n",
        "    else:\n",
        "        print(f\"Error al intentar borrar el índice '{index_name}':\", e.info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQBXij7MMtIP",
        "outputId": "e0ea2b67-6edc-430d-b3ba-282388bc169c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Índice 'my_index' borrado: {'acknowledged': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se define un analizador personalizado **spanish_analyzer** que incluye un filtro de stopwords personalizado custom_spanish_stop con las palabras \"y\" y \"la\"."
      ],
      "metadata": {
        "id": "vRpXOdwkM7t1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_template = {\n",
        "    \"settings\": {\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"spanish_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"standard\",\n",
        "                    \"filter\": [\n",
        "                        \"lowercase\",\n",
        "                        \"custom_spanish_stop\",\n",
        "                        \"spanish_stemmer\"\n",
        "                    ]\n",
        "                }\n",
        "            },\n",
        "            \"filter\": {\n",
        "                \"custom_spanish_stop\": {\n",
        "                    \"type\": \"stop\",\n",
        "                    \"stopwords\": [\"y\", \"los\"]\n",
        "                },\n",
        "                \"spanish_stemmer\": {\n",
        "                    \"type\": \"stemmer\",\n",
        "                    \"language\": \"light_spanish\"\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"title\": {\n",
        "                \"type\": \"text\",\n",
        "                \"analyzer\": \"spanish_analyzer\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "-5r7cCK5MzvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea un indece segun la plantilla creada\n",
        "es.indices.create(index='my_index', body=index_template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0YTpEhoNa8x",
        "outputId": "cd51f5c1-a09b-433b-efaa-401d1f46eb16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'my_index'})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prueba con el analyzer standard\n",
        "text = \"Los zorros son astutos y rápidos\"\n",
        "\n",
        "analyzer = \"standard\"\n",
        "response = es.indices.analyze(index='my_index', body={\n",
        "    'analyzer': analyzer,\n",
        "    'text': text\n",
        "})\n",
        "\n",
        "tokens = [token['token'] for token in response['tokens']]\n",
        "\n",
        "# Imprimimos los tokens analizados\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qJzSev1NztQ",
        "outputId": "55840d1e-3aa1-4264-f8df-107b7a560ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['los', 'zorros', 'son', 'astutos', 'y', 'rápidos']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prueba con el analyzer personalizado\n",
        "text = \"Los zorros son astutos y rápidos\"\n",
        "\n",
        "analyzer = \"spanish_analyzer\"\n",
        "response = es.indices.analyze(index='my_index', body={\n",
        "    'analyzer': analyzer,\n",
        "    'text': text\n",
        "})\n",
        "\n",
        "tokens = [token['token'] for token in response['tokens']]\n",
        "\n",
        "# Imprimimos los tokens analizados\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GVwEaE5N7Fp",
        "outputId": "ba247908-5ef6-4bb4-fdd7-dfa2dcbfabf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['zorr', 'son', 'astut', 'rapid']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actualizar stopwords es más fácil si las especifica en un archivo con el parámetro stopwords_path. Simplemente puede actualizar el archivo (en cada nodo del clúster) y luego obligar a que los analizadores se vuelvan a crear mediante cualquiera de estas acciones:\n",
        "\n",
        "Por supuesto, actualizar la lista de stopwords no cambiará ningún documento que ya haya sido indexado. Se aplicará únicamente a las búsquedas a los documentos nuevos o actualizados. Para aplicar los cambios a los documentos existentes, deberá volver a indexar sus datos. [Consulte Reindexación de sus datos.](https://www.elastic.co/guide/en/elasticsearch/guide/master/reindex.html)"
      ],
      "metadata": {
        "id": "1IJs5-N7QPYS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Correción Ortografia\n",
        "La corrección ortográfica en Elasticsearch es un proceso que permite corregir automáticamente los errores de ortografía en los términos de búsqueda o en los términos indexados en el índice. Esto es especialmente útil cuando los usuarios ingresan consultas de búsqueda con errores de ortografía comunes."
      ],
      "metadata": {
        "id": "mGgpS7WGRw4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Borrar el índice si existe\n",
        "index_name = 'my_index'\n",
        "try:\n",
        "    response = es.indices.delete(index=index_name)\n",
        "    print(f\"Índice '{index_name}' borrado:\", response)\n",
        "except NotFoundError:\n",
        "    print(f\"Índice '{index_name}' no existe, por lo tanto no se borró.\")\n",
        "except RequestError as e:\n",
        "    if e.error == 'index_not_found_exception':\n",
        "        print(f\"Índice '{index_name}' no encontrado, por lo tanto no se borró.\")\n",
        "    else:\n",
        "        print(f\"Error al intentar borrar el índice '{index_name}':\", e.info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_iVJVCFSKmC",
        "outputId": "cb0bdc45-783e-4a06-8e9a-3f1b2d3241da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Índice 'my_index' borrado: {'acknowledged': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se define un analizador personalizado spanish_analyzer que incluye un filtro de corrección ortográfica **spanish_autocorrect**."
      ],
      "metadata": {
        "id": "esb7ww-BSCzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_template =   {\n",
        "    \"settings\": {\n",
        "        \"analysis\": {\n",
        "            \"analyzer\": {\n",
        "                \"spanish_analyzer\": {\n",
        "                    \"type\": \"custom\",\n",
        "                    \"tokenizer\": \"standard\",\n",
        "                    \"filter\": [\n",
        "                        \"lowercase\",\n",
        "                        \"custom_spanish_stop\",\n",
        "                        \"spanish_stemmer\",\n",
        "                        \"spanish_autocorrect\"\n",
        "                    ]\n",
        "                }\n",
        "            },\n",
        "            \"filter\": {\n",
        "                \"custom_spanish_stop\": {\n",
        "                    \"type\": \"stop\",\n",
        "                    \"stopwords\": [\"y\", \"la\"]\n",
        "                },\n",
        "                \"spanish_stemmer\": {\n",
        "                    \"type\": \"stemmer\",\n",
        "                    \"language\": \"light_spanish\"\n",
        "                },\n",
        "                \"spanish_autocorrect\": {\n",
        "                    \"type\": \"hunspell\",\n",
        "                    \"locale\": \"es_ES\",\n",
        "                    \"dedup\": True\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"title\": {\n",
        "                \"type\": \"text\",\n",
        "                \"analyzer\": \"spanish_analyzer\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "ZC41ssPDQQQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para esta funcionalidad, necesita descargar e instalar el diccionario **Hunspell** para el Español. Esta funcionalidad la puede probar con la versión local de ElasticSearch"
      ],
      "metadata": {
        "id": "vm3eMCIJa_rX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JYt0jD_ETCSt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}